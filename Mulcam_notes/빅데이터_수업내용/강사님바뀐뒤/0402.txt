0402

오늘의 팁 : 혹시 s3, s2 에 데이터매니저가 안돌고 있다면 아마도 방화벽이 있을 가능성이 높다.
systemctl stop firewalld
로 꺼주고 jps로 다시 확인해보자

하둡이는 데이터를 분산시켜서 저장함. 한 노드가 꺼졌더라도 안의 데이터를 꺼내 쓸 수 있도록 관리하기 위해
그리고 이렇게 하면 로드가 집중될 수 있는데 로드밸런스가 작동해서 적당하게 부하를 조절

맵 리듀서 만들기
매퍼 - 리듀서 - 필터
분류 - 집계 - 출력


MariaDB [bigdata]> select deptno, count(*) from emp where sal > 1000 group by deptno;

+--------+----------+
| deptno | count(*) |
+--------+----------+
|     10 |        3 |
|     20 |        4 |
|     30 |        5 |
+--------+----------+

mapper가 일을 하기 위해서 전체 데이터셋을 나눠서 입력으로 받는거 큰 테이블을 나눠서 받음
입력이
<0, 7369 스미스 ...20> 식으로 기본적으로 들어온다
매퍼는 입력벨류에서 맨 뒤에 있는 숫자 두개 (어떤 규칙에 따라 ) 를 찾아온다 그 값이 부서번호
<20, 1>
<30, 1>
<30, 1>
식으로 매퍼가 출력하고 그걸 리듀서가 <20, {1,1,1...1}> 식으로 입력을 받음

MariaDB [bigdata]> select d.deptno, d.dname, count(*) from emp e, dept d where sal > 1000 and d.deptno = e.deptno  group by e.deptno;

+--------+------------+----------+
| deptno | dname      | count(*) |
+--------+------------+----------+
|     10 | ACCOUNTING |        3 |
|     20 | RESEARCH   |        4 |
|     30 | SALES      |        5 |
+--------+------------+----------+


입력데이터 셋이 두개인 경우
매퍼도두개가 작동
매퍼 1은 <10, 1> <10, 1>
매퍼 2는 dept데이터를 읽어서 <10, accounting><20, resaerch>
이렇게 키에 부서번호, 벨류에 부서이름으로 분류


이클립스
자바 프로젝트
우클릭
컨피겨레이션
컨버트 투 메이븐 프로젝트
피니쉬~

다음과 같은 라이브러리를 메이븐을 이용해서 우리 프로젝트에 박아넣는다.
우리가 쓰는 개발환경과 동일한 이클립스 환경 만들어주기
[hadoop@s1 ~]$ ls /data/hadoop/hadoop-2.8.2/share/hadoop/common/lib/
activation-1.1.jar                     commons-digester-1.8.jar      htrace-core4-4.0.1-incubating.jar  jets3t-0.9.0.jar            paranamer-2.3.jar
apacheds-i18n-2.0.0-M15.jar            commons-io-2.4.jar            httpclient-4.5.2.jar               jettison-1.1.jar            protobuf-java-2.5.0.jar
apacheds-kerberos-codec-2.0.0-M15.jar  commons-lang-2.6.jar          httpcore-4.4.4.jar                 jetty-6.1.26.jar            servlet-api-2.5.jar
api-asn1-api-1.0.0-M20.jar             commons-logging-1.1.3.jar     jackson-core-asl-1.9.13.jar        jetty-sslengine-6.1.26.jar  slf4j-api-1.7.10.jar
api-util-1.0.0-M20.jar                 commons-math3-3.1.1.jar       jackson-jaxrs-1.9.13.jar           jetty-util-6.1.26.jar       slf4j-log4j12-1.7.10.jar
asm-3.2.jar                            commons-net-3.1.jar           jackson-mapper-asl-1.9.13.jar      jsch-0.1.54.jar             snappy-java-1.0.4.1.jar
avro-1.7.4.jar                         curator-client-2.7.1.jar      jackson-xc-1.9.13.jar              json-smart-1.1.1.jar        stax-api-1.0-2.jar
commons-beanutils-1.7.0.jar            curator-framework-2.7.1.jar   java-xmlbuilder-0.4.jar            jsp-api-2.1.jar             xmlenc-0.52.jar
commons-beanutils-core-1.8.0.jar       curator-recipes-2.7.1.jar     jaxb-api-2.2.2.jar                 jsr305-3.0.0.jar            xz-1.0.jar
commons-cli-1.2.jar                    gson-2.2.4.jar                jaxb-impl-2.2.3-1.jar              junit-4.11.jar              zookeeper-3.4.6.jar
commons-codec-1.4.jar                  guava-11.0.2.jar              jcip-annotations-1.0.jar           log4j-1.2.17.jar
commons-collections-3.2.2.jar          hadoop-annotations-2.8.2.jar  jersey-core-1.9.jar                mockito-all-1.8.5.jar
commons-compress-1.4.1.jar             hadoop-auth-2.8.2.jar         jersey-json-1.9.jar                netty-3.6.2.Final.jar
commons-configuration-1.6.jar          hamcrest-core-1.3.jar         jersey-server-1.9.jar              nimbus-jose-jwt-3.9.jar

위에 보면 하둡에 커먼에 있는 라이브러리임
https://mvnrepository.com/ 에서 하둡을 검색해 common을 설치
Apache Hadoop Common
버전도 일치해야함 (우리는 2.8.2)
pom.xml에 </build> 아래에 <dependances>만들고 안에
디펜던시 복붙 ㄱㄱ
Apache Hadoop MapReduce Core > 2.8.2


컴바인어 - 하둡에 보내기 전에 먼저 집계할 수 있는건 하고 보낸다.
여러 노드들에서 먼저 세어서 보내주는데
대신에 랩핑의 타입이 동일해야함


여튼 간에 소스 팍팍 적어서 만든 것을 프로젝트에서 우클릭 Run as Maven install로 jar로 만든다

만들어진 jar는  target폴더에 들어있는데 그걸 리눅스로 옮긴다. 
리눅스에 옮길 때 user를 하둡으로 옮겨야함
유저에 hadoop 비번은 admin 포트 22임
그래서 옮겨주고나면 
하둡에서 hadoop jar hadoop-0.0.1-SNAPSHOT.jar hadoop.WordCount /ebook /ebook_out5
로 실행시켜준다. 
결과 확인은 hdfs dfs -cat /ebook_out/part-r-00000 | awk '{print $2", " $1}' | sort -nr | more